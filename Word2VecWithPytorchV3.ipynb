{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## pip"
      ],
      "metadata": {
        "id": "BmNi09ugEJGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "e41oSpy2Dw2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "909e6e8c-46cc-4bdc-b46a-633a5ecf9ba1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "4q_rusnnEE2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "iTesZffCEojB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "import string\n",
        "import psutil\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import mode\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, normalizers, decoders, processors\n",
        "import tiktoken\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, Dataset, IterableDataset, DataLoader"
      ],
      "metadata": {
        "id": "SdiamMUaEQzu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "shell = get_ipython()\n",
        "\n",
        "def adjust_font_size():\n",
        "  display(HTML('''<style>\n",
        "    body {\n",
        "      font-size: 24px;\n",
        "    }\n",
        "  '''))\n",
        "\n",
        "if adjust_font_size not in shell.events.callbacks['pre_execute']:\n",
        "  shell.events.register('pre_execute', adjust_font_size)"
      ],
      "metadata": {
        "id": "yPykqb6Q9UNf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwaY_YcgRayy"
      },
      "source": [
        "# ðŸ”´ **Utils**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(tokens, seq_len):\n",
        "    # Trim tokens so that total length is divisible by seq_len\n",
        "    n_tokens = (tokens.shape[0] // seq_len) * seq_len\n",
        "    tokens = tokens[:n_tokens]\n",
        "\n",
        "    # Reshape to 2D tensor\n",
        "    return tokens.view(-1, seq_len)\n"
      ],
      "metadata": {
        "id": "Vp_t8qCRfNCx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "49aba9b3-73a2-4258-d9e0-c32ad2999eb0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PpKbTUEIRayz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d94f5af2-62da-4c28-f095-20f4f8642b0f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def num_trainable_params(model):\n",
        "  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
        "  return nums"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_time(model, x, num_runs=10):\n",
        "    torch.cuda.synchronize()\n",
        "    start = time.time()\n",
        "    for _ in range(num_runs):\n",
        "        model(*x)\n",
        "    torch.cuda.synchronize()\n",
        "    return (time.time() - start) / num_runs\n",
        "\n",
        "\n",
        "def calculate_time_cpu(model, x, num_runs=10):\n",
        "    start = time.time()\n",
        "    for _ in range(num_runs):\n",
        "        model(*x)\n",
        "    return (time.time() - start) / num_runs"
      ],
      "metadata": {
        "id": "G6LDfZvmOLcI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1a81a5b4-8ed1-444d-b7a4-b99d58063791"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŸ¥ tokenize Tiktoken fast"
      ],
      "metadata": {
        "id": "ocpBR9r9E0Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=load_dataset(\"roneneldan/TinyStories\")"
      ],
      "metadata": {
        "id": "RUTUzg-pGeYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e05c352-abff-4d88-c429-df0c58da7b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvHCVoih5Bap",
        "outputId": "66ba7e09-0fc3-48e3-e12a-6596a9d12f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': (2119719, 1), 'validation': (21990, 1)}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
        "tokenized_train_samples = []\n",
        "for item in tqdm(dataset[\"train\"], desc=\"Tokenizing Train Set\"):\n",
        "    input_ids = tokenizer.encode(item[\"text\"])\n",
        "    tokenized_train_samples.append(np.array(input_ids))"
      ],
      "metadata": {
        "id": "n9l5SC43E5zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_valid_samples = []\n",
        "for item in tqdm(dataset[\"validation\"], desc=\"Tokenizing validation Set\"):\n",
        "    input_ids = tokenizer.encode(item[\"text\"])\n",
        "    tokenized_valid_samples.append(np.array(input_ids))"
      ],
      "metadata": {
        "id": "LrN9LZA03mL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_valid_samples[:1]"
      ],
      "metadata": {
        "id": "cc-VMQ0251vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sumtoks=  sum(len(tok) for tok in tokenized_train_samples)\n",
        "print(sumtoks)"
      ],
      "metadata": {
        "id": "EEIO6-sDIUqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŸ¥ Train Bpe Tokenizer and data loader"
      ],
      "metadata": {
        "id": "FfNEUe3ss4LB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŸ§ BPE Trainer"
      ],
      "metadata": {
        "id": "CMYf01JHj07X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a BPE tokenizer\n",
        "tokenizer = Tokenizer(models.BPE(unk_token=\"|<unk>|\"))\n",
        "\n",
        "# Use a pre-tokenizer to split text into words\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
        "\n",
        "# Initialize a BPE trainer\n",
        "trainer = trainers.BpeTrainer(\n",
        "    vocab_size=10_000,  # Set the vocabulary size\n",
        "    special_tokens=[\"|<unk>|\", \"<|endoftext|>\"],\n",
        "    min_frequency=2,  # Set the minimum frequency of tokens\n",
        "    )\n",
        "\n",
        "# Train the tokenizer on a custom dataset\n",
        "tokenizer.train_from_iterator(dataset[\"train\"][\"text\"], trainer)\n",
        "\n",
        "# Add special tokens\n",
        "tokenizer.post_processor = processors.TemplateProcessing(\n",
        "    single=\"<|endoftext|> $A\",\n",
        "    special_tokens=[(\"<|endoftext|>\", tokenizer.token_to_id(\"<|endoftext|>\"))],\n",
        ")\n",
        "\n",
        "# Add decoder\n",
        "tokenizer.decoder = decoders.ByteLevel(add_prefix_space=False)\n",
        "\n",
        "# Save the trained tokenizer\n",
        "tokenizer.save(\"bpe-tokenizer_tinystories.json\")\n",
        "\n",
        "#\n",
        "print(f\"ðŸŽ‰ Tokenizer training complete!\")\n",
        "print(f\"ðŸ”¹ Vocabulary size: {tokenizer.get_vocab_size():,} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0FFXwS3tf9l",
        "outputId": "8d15b6dd-aa76-4fc8-90ad-bb33aa956897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ‰ Tokenizer training complete!\n",
            "ðŸ”¹ Vocabulary size: 10,000 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a BPE tokenizer\n",
        "tokenizer = Tokenizer.from_file(\"bpe-tokenizer_tinystories.json\")\n",
        "print(f\"ðŸŽ‰ Tokenizer training complete!\")\n",
        "print(f\"ðŸ”¹ Vocabulary size: {tokenizer.get_vocab_size():,} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIB3W1p53lOc",
        "outputId": "2a50cb8d-f64b-4b18-f195-d29d7ba8f630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ‰ Tokenizer training complete!\n",
            "ðŸ”¹ Vocabulary size: 10,000 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = 'They played together all day and became best friends.'\n",
        "tokens = tokenizer.encode(sent)\n",
        "print(tokens.ids)\n",
        "print(tokens.tokens)\n",
        "\n",
        "pprint(tokenizer.decode(tokens.ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "798_gzXZuM5x",
        "outputId": "c61d6ab5-d0fa-466b-be29-1535913ea34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 546, 667, 462, 378, 252, 161, 1042, 725, 375, 15]\n",
            "['<|endoftext|>', 'They', 'Ä played', 'Ä together', 'Ä all', 'Ä day', 'Ä and', 'Ä became', 'Ä best', 'Ä friends', '.']\n",
            "'They played together all day and became best friends.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŸ§ Save and load Tokens with BPE tokenizer"
      ],
      "metadata": {
        "id": "H0gmGOkqIAxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization {train}\n",
        "tokenized_train_samples = []\n",
        "for item in tqdm(dataset[\"train\"], desc=\"Tokenizing Train Set\"):\n",
        "    input_ids = tokenizer.encode(item[\"text\"]).ids\n",
        "    tokenized_train_samples.append(np.array(input_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdaDekSJuq03",
        "outputId": "3262bb29-96e9-4d8c-99e3-5ee1b7183552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokenizing Train Set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2119719/2119719 [20:22<00:00, 1733.38it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_samples_concat=[]\n",
        "tokenized_train_samples_concat = np.concatenate(tokenized_train_samples)\n",
        "len(tokenized_train_samples_concat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi9uU-62Nq21",
        "outputId": "b0b15efd-297a-45c3-a5f5-e1939dbdef96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "464965814"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tokens as a pytorch file\n",
        "torch.save(torch.tensor(tokenized_train_samples_concat), 'tokenized-train-samples_vocab-10k.pt')"
      ],
      "metadata": {
        "id": "rt_1F7qvQcfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization {validation}\n",
        "tokenized_valid_samples = []\n",
        "for item in tqdm(dataset[\"validation\"], desc=\"Tokenizing Validation Set\"):\n",
        "    input_ids = tokenizer.encode(item[\"text\"]).ids\n",
        "    tokenized_valid_samples.append(np.array(input_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "On0JGjWju6r7",
        "outputId": "fa01a0a9-f830-410c-9aae-cc53ec1d37bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokenizing Validation Set: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21990/21990 [00:12<00:00, 1822.45it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_valid_samples_concat=[]\n",
        "tokenized_valid_samples_concat = np.concatenate(tokenized_valid_samples)\n",
        "len(tokenized_valid_samples_concat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz6unOJpAshB",
        "outputId": "56f2593c-2631-4a24-bfc9-8f4e47d6d001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4673588"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tokens as a pytorch file\n",
        "torch.save(torch.tensor(tokenized_valid_samples_concat), 'tokenized-valid-samples_vocab-10k.pt')"
      ],
      "metadata": {
        "id": "DB6a7nNC8_tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŸ§ Custom dataset"
      ],
      "metadata": {
        "id": "6c2dBVc4wf-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyStoriesDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, seq_len):\n",
        "        self.seq_len = seq_len\n",
        "        self.data = prepare_data(data, seq_len+1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        return sample[:-1], sample[1:]"
      ],
      "metadata": {
        "id": "1oQvaIZLwkIR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c42ba99e-b6dc-486f-86e6-28a3bbe52363"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = TinyStoriesDataset(tokenized_train_samples, 128)\n",
        "train_set.data.shape, len(train_set), train_set[0]"
      ],
      "metadata": {
        "id": "ZByVGGuUwenF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit next(iter(train_set))"
      ],
      "metadata": {
        "id": "k47DvjFVxOdw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "884e0ff4-29cd-4427-df55-9b2426a55de9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.61 Âµs Â± 192 ns per loop (mean Â± std. dev. of 7 runs, 100000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b=next(iter(train_set))"
      ],
      "metadata": {
        "id": "U0SjBcbtatUz"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(b)"
      ],
      "metadata": {
        "id": "6XCHXYbaaxPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŸ§ DataLoader"
      ],
      "metadata": {
        "id": "x2lJvLkFx-Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "ZrG3JwDrg_9e",
        "outputId": "66a1a7f9-f694-470d-f102-673f86f4fd41"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer.from_file(\"/content/drive/MyDrive/temp/bpe-tokenizer_tinystories.json\")\n",
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "a700lJAToJ9H",
        "outputId": "4b80069b-ab75-4611-8df2-9c6171514e29"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tokenizer(version=\"1.0\", truncation=None, padding=None, added_tokens=[{\"id\":0, \"content\":\"|<unk>|\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":1, \"content\":\"<|endoftext|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}], normalizer=None, pre_tokenizer=ByteLevel(add_prefix_space=False, trim_offsets=True, use_regex=True), post_processor=TemplateProcessing(single=[SpecialToken(id=\"<|endoftext|>\", type_id=0), Sequence(id=A, type_id=0)], pair=[Sequence(id=A, type_id=0), Sequence(id=B, type_id=1)], special_tokens={\"<|endoftext|>\":SpecialToken(id=\"<|endoftext|>\", ids=[1], tokens=[\"<|endoftext|>\"])}), decoder=ByteLevel(add_prefix_space=True, trim_offsets=True, use_regex=True), model=BPE(dropout=None, unk_token=\"|<unk>|\", continuing_subword_prefix=None, end_of_word_suffix=None, fuse_unk=False, byte_fallback=False, ignore_merges=False, vocab={\"|<unk>|\":0, \"<|endoftext|>\":1, \"!\":2, \"\"\":3, \"#\":4, \"$\":5, \"%\":6, \"&\":7, \"'\":8, \"(\":9, \")\":10, \"*\":11, \"+\":12, \",\":13, \"-\":14, \".\":15, \"/\":16, \"0\":17, \"1\":18, \"2\":19, \"3\":20, \"4\":21, \"5\":22, \"6\":23, \"7\":24, \"8\":25, \"9\":26, \":\":27, \";\":28, \"<\":29, \"=\":30, \">\":31, \"?\":32, \"@\":33, \"A\":34, \"B\":35, \"C\":36, \"D\":37, \"E\":38, \"F\":39, \"G\":40, \"H\":41, \"I\":42, \"J\":43, \"K\":44, \"L\":45, \"M\":46, \"N\":47, \"O\":48, \"P\":49, \"Q\":50, \"R\":51, \"S\":52, \"T\":53, \"U\":54, \"V\":55, \"W\":56, \"X\":57, \"Y\":58, \"Z\":59, \"[\":60, \"\\\":61, \"]\":62, \"_\":63, \"`\":64, \"a\":65, \"b\":66, \"c\":67, \"d\":68, \"e\":69, \"f\":70, \"g\":71, \"h\":72, \"i\":73, \"j\":74, \"k\":75, \"l\":76, \"m\":77, \"n\":78, \"o\":79, \"p\":80, \"q\":81, \"r\":82, \"s\":83, \"t\":84, \"u\":85, \"v\":86, \"w\":87, \"x\":88, \"y\":89, \"z\":90, \"{\":91, \"|\":92, \"}\":93, \"~\":94, \"Â¡\":95, \"Â¢\":96, \"Â£\":97, \"Â¤\":98, ...}, merges=[(\"h\", \"e\"), (\"Ä \", \"t\"), (\"Ä \", \"a\"), (\"Ä \", \"s\"), (\"Ä \", \"w\"), (\"n\", \"d\"), (\"Ä t\", \"he\"), (\"e\", \"d\"), (\"Ä a\", \"nd\"), (\"Ä t\", \"o\"), (\"Ä \", \"b\"), (\"i\", \"n\"), (\"Ä \", \"h\"), (\"Ä w\", \"a\"), (\"r\", \"e\"), (\"o\", \"u\"), (\"Ä \", \"f\"), (\"i\", \"t\"), (\"Ä \", \"l\"), (\"Ä \", \"c\"), (\"Ä \", \"d\"), (\"e\", \"r\"), (\"Ä \", \"he\"), (\"Ä \", \"m\"), (\"Ä \", \"p\"), (\"Ä wa\", \"s\"), (\"o\", \"m\"), (\"Ä \", \"T\"), (\"Ä \", \"o\"), (\"a\", \"y\"), (\"a\", \"r\"), (\"i\", \"s\"), (\"in\", \"g\"), (\"i\", \"l\"), (\"Ä \", \"g\"), (\"i\", \"d\"), (\"a\", \"t\"), (\"e\", \"n\"), (\"Ä \", \"n\"), (\"Ä s\", \"a\"), (\"Ä h\", \"a\"), (\"Ä \", \"S\"), (\"Ä T\", \"he\"), (\"a\", \"n\"), (\"i\", \"m\"), (\"o\", \"r\"), (\"o\", \"n\"), (\"Ä \", \"it\"), (\"Ä t\", \"h\"), (\"l\", \"l\"), (\"l\", \"e\"), (\"Ä \", \"H\"), (\"Ä he\", \"r\"), (\"o\", \"t\"), (\"e\", \"t\"), (\"i\", \"r\"), (\"Ä S\", \"he\"), (\"e\", \"s\"), (\"Ä H\", \"e\"), (\"Ä \", \"in\"), (\"v\", \"er\"), (\"u\", \"t\"), (\"o\", \"w\"), (\"Ä The\", \"y\"), (\"c\", \"k\"), (\"Ä \", \"e\"), (\"Ä \", \"u\"), (\"l\", \"d\"), (\"Ä \", \"y\"), (\"o\", \"o\"), (\"Ä sa\", \"id\"), (\"i\", \"g\"), (\"Ä \", \"\"\"), (\"il\", \"y\"), (\"Ä \", \"r\"), (\"Ä b\", \"e\"), (\"a\", \"m\"), (\"Ä s\", \"t\"), (\"Ä \", \"I\"), (\"c\", \"e\"), (\"k\", \"e\"), (\"Ä s\", \"he\"), (\"v\", \"e\"), (\"p\", \"p\"), (\"it\", \"h\"), (\"Ä w\", \"ith\"), (\"L\", \"ily\"), (\"O\", \"n\"), (\"Ä o\", \"n\"), (\"Ä y\", \"ou\"), (\"Ä o\", \"f\"), (\"k\", \"ed\"), (\"r\", \"i\"), (\"Ä s\", \"o\"), (\"n\", \"t\"), (\"Ä h\", \"is\"), (\"Ä p\", \"l\"), (\"a\", \"d\"), (\"ver\", \"y\"), ...]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenized_train_samples = torch.load('/content/drive/MyDrive/temp/tokenized-train-samples_vocab-10k.pt')\n",
        "tokenized_valid_samples = torch.load('/content/drive/MyDrive/temp/tokenized-valid-samples_vocab-10k.pt')\n",
        "\n",
        "# train_set = TinyStoriesDataset(tokenized_train_samples, seq_len=128)\n",
        "valid_set = TinyStoriesDataset(tokenized_valid_samples, seq_len=128)"
      ],
      "metadata": {
        "id": "F5evvjhex63m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6921a15e-c40f-4737-aa04-8358d5322dd8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_loader = DataLoader(train_set, batch_size=32, shuffle=True, pin_memory=True) #, num_workers=2)\n",
        "valid_loader = DataLoader(valid_set, batch_size=32, shuffle=False, pin_memory=True) #, num_workers=2)"
      ],
      "metadata": {
        "id": "0Acjf4UeyMHz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "896b8cc5-eb42-4f33-a14b-e5c09de72264"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(iter(valid_loader))\n",
        "x_batch.shape, y_batch.shape"
      ],
      "metadata": {
        "id": "qkhNsYnMyUwe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "8b615323-4296-4404-fa8d-34348c9c64f8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 128]), torch.Size([32, 128]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_batch[0,:])\n",
        "print('\\n',y_batch[0,:])"
      ],
      "metadata": {
        "id": "YdOkfGMPnnHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader), len(valid_loader)"
      ],
      "metadata": {
        "id": "4Em6sZ_syl2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader) / (20*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICs47WHsftyW",
        "outputId": "73583e6d-7b03-4b65-eaba-b67e11995bba"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93.865"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = iter(train_loader)"
      ],
      "metadata": {
        "id": "ihV-0spZfZhq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit next(train_iter)"
      ],
      "metadata": {
        "id": "_RMcGk_qyojK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŸ§ EDA"
      ],
      "metadata": {
        "id": "wMtdHFsCN2Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_count_stories=[]\n",
        "for tokns in tokenized_train_samples:\n",
        "    token_count_stories.append(len(tokns))"
      ],
      "metadata": {
        "id": "UkQNex4eDn1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_count_stories_np=np.array(token_count_stories)"
      ],
      "metadata": {
        "id": "cxWO9YTOENR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(token_count_stories, bins=50, kde=True)\n",
        "plt.xlabel('Token Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Token Counts')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JRcUm7utIHkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sort(token_count_stories_np)[:1000]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LAGEzHvoN-Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŸ¥ Transformer Model from scratch"
      ],
      "metadata": {
        "id": "vOQNBqhXMuYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAtention(torch.nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        self.qkv_proj = torch.nn.Linear(embed_dim, 3 * embed_dim)\n",
        "        self.out_proj = torch.nn.Linear(embed_dim, embed_dim)\n",
        "    # Ø§Ø­ØªÙ…Ø§Ù„Ø§ Ø®Ø·Ø§ Ø§Ø¨Ø¹Ø§Ø¯ Ø¯Ø§Ø±Ø¯ Ø²Ù…Ø§Ù† ØªØ±ÛŒÙ† Ù…Ù…Ú©Ù† Ø§Ø³Øª ØªØ±ÛŒÙ† Ù†Ø´ÙˆØ¯\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, embed_dim = x.size()\n",
        "        k,q,v = self.qkv_proj(x).view(batch_size, seq_len, 3, self.num_heads, self.head_dim).transpose(1,2).chunk(3)\n",
        "        # F.scaled_dot_product_attention(q,k,v)\n",
        "        # return self.out_proj(x)\n",
        "        return q"
      ],
      "metadata": {
        "id": "E7h7rW2dDss8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.range(1,24).view(2,3,4)\n",
        "print(x)\n",
        "\n",
        "# /x=x.transpose(1,0)\n",
        "print(x)\n",
        "#"
      ],
      "metadata": {
        "id": "cZ0QUKKhQ8hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45892715-5dc8-4be2-9520-f6b2e4676449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.,  2.,  3.,  4.],\n",
            "         [ 5.,  6.,  7.,  8.],\n",
            "         [ 9., 10., 11., 12.]],\n",
            "\n",
            "        [[13., 14., 15., 16.],\n",
            "         [17., 18., 19., 20.],\n",
            "         [21., 22., 23., 24.]]])\n",
            "tensor([[[ 1.,  2.,  3.,  4.],\n",
            "         [ 5.,  6.,  7.,  8.],\n",
            "         [ 9., 10., 11., 12.]],\n",
            "\n",
            "        [[13., 14., 15., 16.],\n",
            "         [17., 18., 19., 20.],\n",
            "         [21., 22., 23., 24.]]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-bc631cf5fcde>:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  x=torch.range(1,24).view(2,3,4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)\n",
        "y= MultiHeadAtention(4,2)(x)\n",
        "y.shape"
      ],
      "metadata": {
        "id": "a0pQHFFuRGNM",
        "outputId": "1a75d0c3-f2ce-4205-8f96-8c73c8d63bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 4])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 3, got 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-fd711f9de565>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mMultiHeadAtention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-89424fe69ebb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# F.scaled_dot_product_attention(q,k,v)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# return self.out_proj(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”´ **Model from scratch - Howsam**"
      ],
      "metadata": {
        "id": "ZnBQs-C8PNrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŸ  Define"
      ],
      "metadata": {
        "id": "oIjl-VOXpzAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "TBwuEJI6NNNg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7f960094-7c11-4360-8d68-1a45b14d6be4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "VuXbNcH1p7mv",
        "outputId": "384e25d1-e5e6-45ef-bbbd-4cdc5257f9cb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŸ  Embedding"
      ],
      "metadata": {
        "id": "oP9PxAiBOXG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wte = nn.Embedding(tokenizer.get_vocab_size(), 100)\n",
        "wte(torch.tensor([1, 2,3])).shape"
      ],
      "metadata": {
        "id": "D3KuSAfszsHf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "784a768a-4481-4199-8c38-73b181d8b86c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 128\n",
        "wpe = nn.Embedding(seq_len, 100)\n",
        "wpe(torch.tensor([1, 2, 100])).shape"
      ],
      "metadata": {
        "id": "NN6B1P0tzsBF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "a8960d65-bc9e-4a82-e38b-68de7f81d9b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wpe(torch.arange(x_batch.shape[1])).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "qWFIHM3x-26z",
        "outputId": "56a93952-0397-4e7b-8039-da5e3ed055a6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = wte(x_batch) + wpe(torch.arange(x_batch.shape[1]))\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "AMgXEhAwIJxj",
        "outputId": "906733c9-04da-4ca8-8c22-50e31c718b35"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 128, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŸ  Scaled Dot-Product Attention"
      ],
      "metadata": {
        "id": "CHJ4NWXGR0YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q = k = v = x\n",
        "print(q.shape)\n",
        "\n",
        "mask = torch.tril(torch.ones(seq_len, seq_len))\n",
        "\n",
        "scores = q @ k.transpose(-2, -1) / (k.shape[-1]**0.5)\n",
        "scores.masked_fill_(mask ==0, float(-torch.inf))\n",
        "scores = scores.softmax(dim=-1)\n",
        "print(scores.shape)\n",
        "\n",
        "z = scores @ v\n",
        "z.shape"
      ],
      "metadata": {
        "id": "9j_qy0aIJZXl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "60128ac0-276e-4d1c-e656-31cfe2458773"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 128, 100])\n",
            "torch.Size([32, 128, 128])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 128, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scores = torch.randn(3, 5, 5)\n",
        "# mask = torch.tril(torch.ones(5, 5))\n",
        "# scores.masked_fill_(mask ==0, float(-torch.inf))\n",
        "# scores = scores.softmax(dim=-1)\n",
        "# scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QptCjesZL96l",
        "outputId": "96a4d348-e97e-4995-f008-3c69df71aee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v):\n",
        "    mask = torch.tril(torch.ones(q.shape[-2], q.shape[-2])).to(device)\n",
        "    scores = q @ k.transpose(-2, -1) / (k.shape[-1]**0.5)\n",
        "    scores.masked_fill_(mask==0, float(-torch.inf))\n",
        "    scores = scores.softmax(dim=-1)\n",
        "    z = scores @ v\n",
        "    return z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mIEMC-FarKJ1",
        "outputId": "0aefd39b-a729-46b9-fc6d-e1ea14d8d61c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_dot_product_attention(x.to(device), x.to(device), x.to(device)).shape"
      ],
      "metadata": {
        "id": "wdt56H82PQqN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "outputId": "e6ff4296-ba14-426e-8d90-076289268932"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 128, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = torch.randn((128, 1024, 768), device=device)\n",
        "k = torch.randn((128, 1024, 768), device=device)\n",
        "v = torch.randn((128, 1024, 768), device=device)\n",
        "q.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "xK6XgVlePa0n",
        "outputId": "5c70a8c1-2eba-4df0-a62f-80a1ebd6259c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_dot_product_attention(q, k, v).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "5COTL0OKPxY1",
        "outputId": "32197616-9346-4f31-ce22-4371f7d45442"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate_time(scaled_dot_product_attention, (q, k, v), num_runs=20)\n",
        "calculate_time_cpu(scaled_dot_product_attention, (q, k, v), num_runs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "LsaSSCkaQLtw",
        "outputId": "df926cc1-77af-4070-8f66-5b533619effa",
        "collapsed": true
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.620952212810517"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.scaled_dot_product_attention(q, k, v, is_causal=True).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "UmCJ2BV6Unge",
        "outputId": "0ec3667e-1361-47f6-8d04-d05d2a443249"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.abs(scaled_dot_product_attention(q, k, v) - F.scaled_dot_product_attention(q, k, v, is_causal=True)).max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "IjrAqzTWU79x",
        "outputId": "c63bfc67-01bd-43a3-f430-0d95988c6d07"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.9073e-06)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_time(F.scaled_dot_product_attention, (q, k, v), num_runs=20)"
      ],
      "metadata": {
        "id": "cnGXNViJVWzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŸ  Multi Head Attention"
      ],
      "metadata": {
        "id": "rUjFcYeiIE9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class MultiHeadAttention(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.fc1 = nn.Linear(100, 1000)\n",
        "#         self.fc2 = nn.Linear(1000, 100)\n",
        "#         self.fc3 = nn.Linear(1000, 100)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         y = F.relu(self.fc1(x))\n",
        "#         y1 = self.fc2(y)\n",
        "#         y2 = self.fc3(y)\n",
        "#         return F.relu(torch.concat([y1, y2], dim=-1))"
      ],
      "metadata": {
        "id": "gnxYy1oIQcY-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "601d8702-3d97-430e-affc-d934c8994ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mha = MultiHeadAttention()\n",
        "# num_trainable_params(mha)\n",
        "# mha.forward(torch.rand(10, 100)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Et6wVx6f7HmB",
        "outputId": "3271b803-66f5-40db-80b8-de54a91a19df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x=torch.randn(2,4)\n",
        "# print(x)\n",
        "# lx=nn.Linear(4,8,bias=False)\n",
        "# y1 =x@ lx.weight.T\n",
        "# y2=lx(x)\n",
        "# print(y1.softmax(dim=-1).argmax(dim=0))\n",
        "# print(y1.softmax(dim=-1))\n",
        "# print(lx.weight.T.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7FtEClDCBhKQ",
        "outputId": "b869524b-2324-415f-8448-eeb4dbad62cf"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTConfig:\n",
        "    n_embd: int = 100\n",
        "    n_head: int = 5\n",
        "\n",
        "config = GPTConfig()\n",
        "config.n_embd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "q10jLOLsuzxi",
        "outputId": "f4e73b02-79e6-4755-95cc-fc414d1d098a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.n_embd = config.n_embd\n",
        "        self.n_head = config.n_head\n",
        "        self.head_size = self.n_embd // self.n_head\n",
        "\n",
        "        self.qkv_proj = nn.Linear(self.n_embd, 3*self.n_embd, bias=False)\n",
        "\n",
        "        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
        "        self.c_proj.residual = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q, k, v = self.qkv_proj(x).view(B, T, 3*self.n_head, self.head_size).transpose(1, 2).chunk(3, dim=-3)\n",
        "\n",
        "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
        "\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "\n",
        "        y = self.c_proj(y)\n",
        "        return y ,q, k, v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2X9b79Iq8l38",
        "outputId": "23128a3f-6945-48a4-fc3a-a01e0dbde860"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mha = MultiHeadAttention(config)\n",
        "y,q, k, v= mha(x)\n",
        "print(\"X:\",x.shape)\n",
        "print(\"qkv_proj:\",mha.qkv_proj.weight.T.shape)\n",
        "print(\"c_proj:\",mha.c_proj.weight.T.shape)\n",
        "\n",
        "print(\"q:\",q.shape)\n",
        "print(k.shape)\n",
        "print(v.shape)\n",
        "print(\"y:\",y.shape)\n",
        "# mha(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "vA3Nw2Riv1Ns",
        "outputId": "f88a6898-6dbe-4ec1-b8ce-f27f703643ec"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: torch.Size([32, 128, 100])\n",
            "qkv_proj: torch.Size([100, 300])\n",
            "c_proj: torch.Size([100, 100])\n",
            "q: torch.Size([32, 5, 128, 20])\n",
            "torch.Size([32, 5, 128, 20])\n",
            "torch.Size([32, 5, 128, 20])\n",
            "y: torch.Size([32, 128, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_time(mha.to(device), (x.to(device),), num_runs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "3YRyw8Hu-bXz",
        "outputId": "992034e8-48cc-43b0-8f11-790a415ca2c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0009491205215454102"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŸ  Feed Forward (MLP)"
      ],
      "metadata": {
        "id": "WTVewgG-m7nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTConfig:\n",
        "    n_embd: int = 100\n",
        "    n_head: int = 5\n",
        "    f_expnd: float = 4\n",
        "\n",
        "config = GPTConfig()\n",
        "config.n_embd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "R-r7XatDAP4B",
        "outputId": "f7cb4738-3649-467a-ace4-7336f50d6a83"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.n_embd = config.n_embd\n",
        "        self.f_expnd = config.f_expnd\n",
        "\n",
        "        self.up_proj = nn.Linear(self.n_embd, int(self.f_expnd*self.n_embd), bias=False)\n",
        "        self.down_proj = nn.Linear(int(self.f_expnd*self.n_embd), self.n_embd, bias=False)\n",
        "        self.down_proj.residual = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.down_proj(F.gelu(self.up_proj(x)))"
      ],
      "metadata": {
        "id": "BTcx4J5Lm66z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "aa07794c-9c35-4b27-e428-dd39e91d981f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feedfor = FeedForward(config)\n",
        "feedfor(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "aDU2oB-PAfXX",
        "outputId": "0dc05577-3a58-42d1-85c1-f4124740b903"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 128, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trainable_params(feedfor)*1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "JtLY269MBHD3",
        "outputId": "0f466594-3194-4d8d-a38e-dd1b7063f0b6"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.0"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_time(mlp, (x, ), num_runs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "FKYxPvrzBQbw",
        "outputId": "ef6f436d-0b79-432d-9769-bd5b2b63cd96"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-4f8313f192ab>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalculate_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_runs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-d9e6e73ce4b3>\u001b[0m in \u001b[0;36mcalculate_time\u001b[0;34m(model, x, num_runs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_runs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36msynchronize\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     \"\"\"\n\u001b[0;32m--> 983\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_synchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŸ  Decoder Block"
      ],
      "metadata": {
        "id": "ih6sV9ljndzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.n_embd = config.n_embd\n",
        "\n",
        "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
        "        self.mha = MultiHeadAttention(config)\n",
        "\n",
        "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = FeedForward(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.mha(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "Gq1kw31av9DR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "94177efc-c17a-4c7e-9f4f-53307327bd63"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = DecoderBlock(config)\n",
        "decoder(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "AweCYj03EtPy",
        "outputId": "4b28b38b-dcdd-4e38-e12d-05d45d6434b3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 128, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trainable_params(decoder) * 1e3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "pO5KeXeLFmDk",
        "outputId": "39cd5793-9f62-4a5b-9246-adc65e286385"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120.39999999999999"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_time_cpu(decoder, (x, ), num_runs=20) * 1e3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "7zAYllgcFsfg",
        "outputId": "88afe093-aaf2-4a2a-9702-9a8ed1a2f320"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33.37346315383911"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŸ  GPT"
      ],
      "metadata": {
        "id": "LCzTHf8iitEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTConfig:\n",
        "    vocab_size: int = 10_000\n",
        "    seq_len: int = 128\n",
        "    n_layer: int = 12\n",
        "    n_embd: int = 100\n",
        "    n_head: int = 5\n",
        "    f_expnd: float = 4\n",
        "\n",
        "\n",
        "config = GPTConfig()\n",
        "config.n_embd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "adRz9KC8HbbT",
        "outputId": "b7239807-f731-43b6-cbfd-a0ec51db5f14"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.wte = nn.Embedding(config.vocab_size, config.n_embd)\n",
        "        self.wpe = nn.Embedding(config.seq_len, config.n_embd)\n",
        "        # self.decoders = nn.Sequential(*[DecoderBlock(config) for _ in range(config.n_layer)])\n",
        "        self.decoders = nn.ModuleList([DecoderBlock(config) for _ in range(config.n_layer)])\n",
        "        self.lnf = nn.LayerNorm(config.n_embd)\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "\n",
        "        self.lm_head.weight = self.wte.weight\n",
        "        # self.lm_head.weight.data.uniform_(-1/self.lm_head.in_features**0.5, 1/self.lm_head.in_features**0.5)\n",
        "        # nn.init.uniform_(self.lm_head.weight, -1/self.lm_head.in_features**0.5, 1/self.lm_head.in_features**0.5)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        std = 0.02\n",
        "        if isinstance(module, nn.Linear):\n",
        "            if hasattr(module, 'residual'):\n",
        "                std *= (2*self.config.n_layer)**-0.5\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=std)\n",
        "            if module.bias is not None:\n",
        "                nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=std)\n",
        "\n",
        "    def forward(self, idx):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        x = self.wte(idx) + self.wpe(torch.arange(T, device=device))\n",
        "\n",
        "        # x = self.decoders(x)\n",
        "        for decoder in self.decoders:\n",
        "            x = decoder(x)\n",
        "\n",
        "        x = self.lnf(x)\n",
        "        logits = self.lm_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "Lmrc034JwvSS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "210410ff-5448-4597-9ea1-f78da8799100"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT(config).to(device)\n",
        "model(x_batch.to(device)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "FwYwWZ_Z-dV-",
        "outputId": "5ca52b94-f5c1-4936-aa87-fb37dacdaccd"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 128, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trainable_params(model), num_trainable_params(model.decoders), num_trainable_params(model.lm_head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "JdecDmI3-rvN",
        "outputId": "21e72a12-5150-4271-f61f-409f8b3e4197"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.4578, 1.4448, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_time(model, (x_batch.to(device),), num_runs=100) * 1e3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "gxIo0WS7-z9b",
        "outputId": "e2947ea0-fa16-46d5-af22-cb741f513a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.62372875213623"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŸ  Initialization"
      ],
      "metadata": {
        "id": "KEnoziDiCZ84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT(\n",
        "    GPTConfig).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UVGTRYO9FH3O",
        "outputId": "ebe9fbaf-eb44-4a8b-b0fb-29141d04e889"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(model.decoders[0].mha.c_proj.weight.flatten().detach().cpu(), bins=50);"
      ],
      "metadata": {
        "id": "dy1ErMbaCeNo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "148eac11-784b-4f27-ed9a-304188cad0dc"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGdCAYAAADuR1K7AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKPxJREFUeJzt3X90VPWd//FXQsjwy5kQIDPJGn5YFUgF0SBh1ForKZGmVde4VjaL1MMRZQNV4lLIOQgt7RpEt7hYgdZtAbdSWk4VKwg2BItbGQKkUJEfWXShoQ2TWDEZYEsSyOf7h9/cdZpIM2QmA588H+fcI3PvZ+58Pm/CzcvP/TEJxhgjAAAASyTGuwMAAADRRLgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFglKd4duBgtLS2qqanRFVdcoYSEhHh3BwAAdIAxRqdOnVJGRoYSE2M3v3JZhpuamhplZmbGuxsAAOAiHD9+XFdeeWXM9n9ZhpsrrrhC0ifFcbvdce4NAADoiFAopMzMTOf3eKxcluGm9VSU2+0m3AAAcJmJ9SUlXFAMAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYJWkeHcAQPwNnbfpb7Y5tji/C3oCAJ3HzA0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKwScbj505/+pH/6p3/SgAED1Lt3b40aNUp79uxxthtjtGDBAqWnp6t3797Kzc3VkSNHwvZx8uRJFRYWyu12KyUlRdOmTdPp06c7PxoAANDtJUXS+OOPP9Ytt9yiL33pS9q8ebMGDRqkI0eOqH///k6bJUuWaNmyZVqzZo2GDRumJ598Unl5eTp48KB69eolSSosLNSJEydUVlam5uZmPfTQQ5o+fbrWrl0b3dEBlhs6b9PfbHNscX4X9AQALh0RhZunn35amZmZWrVqlbNu2LBhzp+NMXruuec0f/583X333ZKkl156SV6vVxs2bNADDzygQ4cOacuWLdq9e7fGjh0rSXr++ef1la98Rc8++6wyMjKiMS4AANBNRXRa6le/+pXGjh2rf/iHf1BaWppuuOEGvfjii872o0ePKhgMKjc311nn8XiUk5OjQCAgSQoEAkpJSXGCjSTl5uYqMTFRFRUV7X5uY2OjQqFQ2AIAANCeiMLN//zP/2jFihW65ppr9Oabb2rGjBn65je/qTVr1kiSgsGgJMnr9Ya9z+v1OtuCwaDS0tLCticlJSk1NdVp89dKS0vl8XicJTMzM5JuAwCAbiSicNPS0qIbb7xRTz31lG644QZNnz5dDz/8sFauXBmr/kmSSkpK1NDQ4CzHjx+P6ecBAIDLV0TX3KSnpysrKyts3ciRI/XLX/5SkuTz+SRJtbW1Sk9Pd9rU1tZqzJgxTpu6urqwfZw7d04nT5503v/XXC6XXC5XJF0FEGVcvAzgchHRzM0tt9yiqqqqsHX//d//rSFDhkj65OJin8+n8vJyZ3soFFJFRYX8fr8kye/3q76+XpWVlU6bbdu2qaWlRTk5ORc9EAAAACnCmZvZs2fr5ptv1lNPPaX7779fu3bt0o9+9CP96Ec/kiQlJCTo8ccf1/e+9z1dc801zq3gGRkZuueeeyR9MtNz5513OqezmpubNXPmTD3wwAPcKQUAADotonBz00036dVXX1VJSYkWLVqkYcOG6bnnnlNhYaHT5lvf+pbOnDmj6dOnq76+Xrfeequ2bNniPONGkl5++WXNnDlTEyZMUGJiogoKCrRs2bLojQqAoyOnkwDAJgnGGBPvTkQqFArJ4/GooaFBbrc73t0BYuJyDCVccwPgQrrq9zffLQUAAKwS0WkpALgQ7qgCcClg5gYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsAoP8QPQpXjQH4BYY+YGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsEpSvDsAdEdD522KdxcAwFrM3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYJaJw8+1vf1sJCQlhy4gRI5ztZ8+eVVFRkQYMGKB+/fqpoKBAtbW1Yfuorq5Wfn6++vTpo7S0NM2ZM0fnzp2LzmgAAEC3lxTpGz7/+c9r69at/7eDpP/bxezZs7Vp0yatX79eHo9HM2fO1L333qt33nlHknT+/Hnl5+fL5/Npx44dOnHihB588EH17NlTTz31VBSGAwAAuruIw01SUpJ8Pl+b9Q0NDfrxj3+stWvX6o477pAkrVq1SiNHjtTOnTs1fvx4/frXv9bBgwe1detWeb1ejRkzRt/97nc1d+5cffvb31ZycnLnRwTE2dB5m+LdBQDo1iK+5ubIkSPKyMjQVVddpcLCQlVXV0uSKisr1dzcrNzcXKftiBEjNHjwYAUCAUlSIBDQqFGj5PV6nTZ5eXkKhUI6cODAZ35mY2OjQqFQ2AIAANCeiMJNTk6OVq9erS1btmjFihU6evSovvCFL+jUqVMKBoNKTk5WSkpK2Hu8Xq+CwaAkKRgMhgWb1u2t2z5LaWmpPB6Ps2RmZkbSbQAA0I1EdFpq0qRJzp9Hjx6tnJwcDRkyRL/4xS/Uu3fvqHeuVUlJiYqLi53XoVCIgAMAANrVqVvBU1JSdO211+r999+Xz+dTU1OT6uvrw9rU1tY61+j4fL42d0+1vm7vOp5WLpdLbrc7bAEAAGhPp8LN6dOn9cEHHyg9PV3Z2dnq2bOnysvLne1VVVWqrq6W3++XJPn9fu3fv191dXVOm7KyMrndbmVlZXWmKwAAAJIiPC31L//yL/ra176mIUOGqKamRgsXLlSPHj00efJkeTweTZs2TcXFxUpNTZXb7dasWbPk9/s1fvx4SdLEiROVlZWlKVOmaMmSJQoGg5o/f76KiorkcrliMkAAANC9RBRu/vjHP2ry5Mn66KOPNGjQIN16663auXOnBg0aJElaunSpEhMTVVBQoMbGRuXl5Wn58uXO+3v06KGNGzdqxowZ8vv96tu3r6ZOnapFixZFd1QAAKDbSjDGmHh3IlKhUEgej0cNDQ1cf4NLDs+56bxji/Pj3QUAMdBVv7/5bikAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsEpE3y0FAF2hI19hwVc0APgszNwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFW8GBCHTkFmUAQHwxcwMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACskhTvDgBArAydt+lvtjm2OL8LegKgKzFzAwAArEK4AQAAViHcAAAAq3DNDYDLUkeupwHQPTFzAwAArEK4AQAAVulUuFm8eLESEhL0+OOPO+vOnj2roqIiDRgwQP369VNBQYFqa2vD3lddXa38/Hz16dNHaWlpmjNnjs6dO9eZrgAAAEjqRLjZvXu3fvjDH2r06NFh62fPnq3XX39d69ev1/bt21VTU6N7773X2X7+/Hnl5+erqalJO3bs0Jo1a7R69WotWLDg4kcBAADw/11UuDl9+rQKCwv14osvqn///s76hoYG/fjHP9b3v/993XHHHcrOztaqVau0Y8cO7dy5U5L061//WgcPHtRPf/pTjRkzRpMmTdJ3v/tdvfDCC2pqaorOqAAAQLd1UeGmqKhI+fn5ys3NDVtfWVmp5ubmsPUjRozQ4MGDFQgEJEmBQECjRo2S1+t12uTl5SkUCunAgQMX0x0AAABHxLeCr1u3Tr/73e+0e/fuNtuCwaCSk5OVkpIStt7r9SoYDDptPh1sWre3bmtPY2OjGhsbndehUCjSbgMAgG4iopmb48eP67HHHtPLL7+sXr16xapPbZSWlsrj8ThLZmZml302AAC4vEQUbiorK1VXV6cbb7xRSUlJSkpK0vbt27Vs2TIlJSXJ6/WqqalJ9fX1Ye+rra2Vz+eTJPl8vjZ3T7W+bm3z10pKStTQ0OAsx48fj6TbAACgG4ko3EyYMEH79+/Xvn37nGXs2LEqLCx0/tyzZ0+Vl5c776mqqlJ1dbX8fr8kye/3a//+/aqrq3PalJWVye12Kysrq93PdblccrvdYQsAAEB7Irrm5oorrtB1110Xtq5v374aMGCAs37atGkqLi5Wamqq3G63Zs2aJb/fr/Hjx0uSJk6cqKysLE2ZMkVLlixRMBjU/PnzVVRUJJfLFaVhAQCA7irq3y21dOlSJSYmqqCgQI2NjcrLy9Py5cud7T169NDGjRs1Y8YM+f1+9e3bV1OnTtWiRYui3RUAANANJRhjTLw7EalQKCSPx6OGhgZOUaFL8WWN9jm2OD/eXQC6ja76/c13SwEAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFWS4t0B4FIxdN6meHcBABAFzNwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKvwhGJ0Czx9GAC6D2ZuAACAVQg3AADAKoQbAABgFa65AdCtdeR6rGOL87ugJwCihZkbAABgFcINAACwSkThZsWKFRo9erTcbrfcbrf8fr82b97sbD979qyKioo0YMAA9evXTwUFBaqtrQ3bR3V1tfLz89WnTx+lpaVpzpw5OnfuXHRGAwAAur2Iws2VV16pxYsXq7KyUnv27NEdd9yhu+++WwcOHJAkzZ49W6+//rrWr1+v7du3q6amRvfee6/z/vPnzys/P19NTU3asWOH1qxZo9WrV2vBggXRHRUAAOi2EowxpjM7SE1N1TPPPKP77rtPgwYN0tq1a3XfffdJkg4fPqyRI0cqEAho/Pjx2rx5s7761a+qpqZGXq9XkrRy5UrNnTtXH374oZKTkzv0maFQSB6PRw0NDXK73Z3pProJHuKHzuCCYiA6uur390Vfc3P+/HmtW7dOZ86ckd/vV2VlpZqbm5Wbm+u0GTFihAYPHqxAICBJCgQCGjVqlBNsJCkvL0+hUMiZ/WlPY2OjQqFQ2AIAANCeiMPN/v371a9fP7lcLj366KN69dVXlZWVpWAwqOTkZKWkpIS193q9CgaDkqRgMBgWbFq3t277LKWlpfJ4PM6SmZkZabcBAEA3EXG4GT58uPbt26eKigrNmDFDU6dO1cGDB2PRN0dJSYkaGhqc5fjx4zH9PAAAcPmK+CF+ycnJuvrqqyVJ2dnZ2r17t/793/9dX//619XU1KT6+vqw2Zva2lr5fD5Jks/n065du8L213o3VWub9rhcLrlcrki7CgAAuqFOP+empaVFjY2Nys7OVs+ePVVeXu5sq6qqUnV1tfx+vyTJ7/dr//79qqurc9qUlZXJ7XYrKyurs10BAACIbOampKREkyZN0uDBg3Xq1CmtXbtWv/nNb/Tmm2/K4/Fo2rRpKi4uVmpqqtxut2bNmiW/36/x48dLkiZOnKisrCxNmTJFS5YsUTAY1Pz581VUVMTMDAAAiIqIwk1dXZ0efPBBnThxQh6PR6NHj9abb76pL3/5y5KkpUuXKjExUQUFBWpsbFReXp6WL1/uvL9Hjx7auHGjZsyYIb/fr759+2rq1KlatGhRdEcFAAC6rU4/5yYeeM4NIsVzbtAZPOcGiI5L/jk3AAAAlyLCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVSL+bikA6G468pwknoUDXDqYuQEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYJSneHQA6a+i8TfHuAgDgEsLMDQAAsAozNwAQBR2ZQTy2OL8LegKAmRsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKkmRNC4tLdUrr7yiw4cPq3fv3rr55pv19NNPa/jw4U6bs2fP6oknntC6devU2NiovLw8LV++XF6v12lTXV2tGTNm6K233lK/fv00depUlZaWKikpou6gGxg6b1O8uwAAuMxENHOzfft2FRUVaefOnSorK1Nzc7MmTpyoM2fOOG1mz56t119/XevXr9f27dtVU1Oje++919l+/vx55efnq6mpSTt27NCaNWu0evVqLViwIHqjAgAA3VaCMcZc7Js//PBDpaWlafv27brtttvU0NCgQYMGae3atbrvvvskSYcPH9bIkSMVCAQ0fvx4bd68WV/96ldVU1PjzOasXLlSc+fO1Ycffqjk5OS/+bmhUEgej0cNDQ1yu90X231cBpi5gU2OLc6PdxeAuOqq39+duuamoaFBkpSamipJqqysVHNzs3Jzc502I0aM0ODBgxUIBCRJgUBAo0aNCjtNlZeXp1AopAMHDrT7OY2NjQqFQmELAABAey463LS0tOjxxx/XLbfcouuuu06SFAwGlZycrJSUlLC2Xq9XwWDQafPpYNO6vXVbe0pLS+XxeJwlMzPzYrsNAAAsd9HhpqioSO+9957WrVsXzf60q6SkRA0NDc5y/PjxmH8mAAC4PF3U7UkzZ87Uxo0b9fbbb+vKK6901vt8PjU1Nam+vj5s9qa2tlY+n89ps2vXrrD91dbWOtva43K55HK5LqarAACgm4lo5sYYo5kzZ+rVV1/Vtm3bNGzYsLDt2dnZ6tmzp8rLy511VVVVqq6ult/vlyT5/X7t379fdXV1TpuysjK53W5lZWV1ZiwAAACRzdwUFRVp7dq1eu2113TFFVc418h4PB717t1bHo9H06ZNU3FxsVJTU+V2uzVr1iz5/X6NHz9ekjRx4kRlZWVpypQpWrJkiYLBoObPn6+ioiJmZwAAQKdFFG5WrFghSbr99tvD1q9atUrf+MY3JElLly5VYmKiCgoKwh7i16pHjx7auHGjZsyYIb/fr759+2rq1KlatGhR50YCAACgTj7nJl54zk33wXNuYBOec4Pu7rJ4zg0AAMClhnADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFjlor4VHAAQuY48cZunGAOdx8wNAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqyTFuwPovobO2xTvLgAALMTMDQAAsAozNwBwCenIjOaxxfld0BPg8sXMDQAAsArhBgAAWIVwAwAArMI1N4gJ7oQCAMQLMzcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKwScbh5++239bWvfU0ZGRlKSEjQhg0bwrYbY7RgwQKlp6erd+/eys3N1ZEjR8LanDx5UoWFhXK73UpJSdG0adN0+vTpTg0EAABAuohwc+bMGV1//fV64YUX2t2+ZMkSLVu2TCtXrlRFRYX69u2rvLw8nT171mlTWFioAwcOqKysTBs3btTbb7+t6dOnX/woAAAA/r+In3MzadIkTZo0qd1txhg999xzmj9/vu6++25J0ksvvSSv16sNGzbogQce0KFDh7Rlyxbt3r1bY8eOlSQ9//zz+spXvqJnn31WGRkZnRgOAADo7qJ6zc3Ro0cVDAaVm5vrrPN4PMrJyVEgEJAkBQIBpaSkOMFGknJzc5WYmKiKiop299vY2KhQKBS2AAAAtCeq4SYYDEqSvF5v2Hqv1+tsCwaDSktLC9uelJSk1NRUp81fKy0tlcfjcZbMzMxodhsAAFjksrhbqqSkRA0NDc5y/PjxeHcJAABcoqIabnw+nySptrY2bH1tba2zzefzqa6uLmz7uXPndPLkSafNX3O5XHK73WELAABAe6IaboYNGyafz6fy8nJnXSgUUkVFhfx+vyTJ7/ervr5elZWVTptt27appaVFOTk50ewOAADohiK+W+r06dN6//33nddHjx7Vvn37lJqaqsGDB+vxxx/X9773PV1zzTUaNmyYnnzySWVkZOiee+6RJI0cOVJ33nmnHn74Ya1cuVLNzc2aOXOmHnjgAe6UAgAAnRZxuNmzZ4++9KUvOa+Li4slSVOnTtXq1av1rW99S2fOnNH06dNVX1+vW2+9VVu2bFGvXr2c97z88suaOXOmJkyYoMTERBUUFGjZsmVRGA4AAOjuEowxJt6diFQoFJLH41FDQwPX31yihs7bFO8uANY6tjg/3l0ALkpX/f6+LO6WAgAA6CjCDQAAsErE19wAAOKrI6d9OXWF7oyZGwAAYBXCDQAAsAqnpRAx7oQCAFzKmLkBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsEpSvDuAS8vQeZvi3QUAADqFcAMAForW/6gcW5wflf0AXYnTUgAAwCrM3HQjnHICAHQHhBtLEFwAAPgEp6UAAIBVCDcAAMAqnJYCAHymjpzy5o4qXGqYuQEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsAq3gl8GePowAAAdx8wNAACwCuEGAABYhdNSAIBO4SnGuNQQbgAAMUcAQlfitBQAALAK4QYAAFiF01IxxC3cAAB0vbjO3LzwwgsaOnSoevXqpZycHO3atSue3QEAABaIW7j5+c9/ruLiYi1cuFC/+93vdP311ysvL091dXXx6hIAALBAgjHGxOODc3JydNNNN+kHP/iBJKmlpUWZmZmaNWuW5s2bd8H3hkIheTweNTQ0yO12d0V32+CUEwBcvrgzKz666vd3XK65aWpqUmVlpUpKSpx1iYmJys3NVSAQaNO+sbFRjY2NzuuGhgZJnxQpFq5b+GZM9gsAuDTE6vcHLqy17rGeV4lLuPnzn/+s8+fPy+v1hq33er06fPhwm/alpaX6zne+02Z9ZmZmzPoIALCX57l496B7O3XqlDweT8z2f1ncLVVSUqLi4mLndUtLi06ePKkBAwYoISFBoVBImZmZOn78eNxOU12KqEtb1KR91KV91KUtatI+6tK+v66LMUanTp1SRkZGTD83LuFm4MCB6tGjh2pra8PW19bWyufztWnvcrnkcrnC1qWkpLRp53a7+aFqB3Vpi5q0j7q0j7q0RU3aR13a9+m6xHLGplVc7pZKTk5Wdna2ysvLnXUtLS0qLy+X3++PR5cAAIAl4nZaqri4WFOnTtXYsWM1btw4Pffcczpz5oweeuiheHUJAABYIG7h5utf/7o+/PBDLViwQMFgUGPGjNGWLVvaXGTcES6XSwsXLmxz6qq7oy5tUZP2UZf2UZe2qEn7qEv74lWXuD3nBgAAIBb44kwAAGAVwg0AALAK4QYAAFiFcAMAAKxySYabkydPqrCwUG63WykpKZo2bZpOnz59wfecPXtWRUVFGjBggPr166eCgoI2Dwn85je/qezsbLlcLo0ZM6bNPo4dO6aEhIQ2y86dO6M5vIsWr7pI0rvvvqsvfOEL6tWrlzIzM7VkyZJoDatTYlWT6upq5efnq0+fPkpLS9OcOXN07tw5Z/tvfvObdn9WgsFgTMb5t7zwwgsaOnSoevXqpZycHO3ateuC7devX68RI0aoV69eGjVqlN54442w7cYYLViwQOnp6erdu7dyc3N15MiRsDYXU/uuFo+6DB06tM3PxeLFi6M+ts6Idl1eeeUVTZw40Xlq/L59+9rsoyP/7uIpHjW5/fbb2/ysPProo9EcVqdFsy7Nzc2aO3euRo0apb59+yojI0MPPvigampqwvYRlWOLuQTdeeed5vrrrzc7d+40//Vf/2WuvvpqM3ny5Au+59FHHzWZmZmmvLzc7Nmzx4wfP97cfPPNYW1mzZplfvCDH5gpU6aY66+/vs0+jh49aiSZrVu3mhMnTjhLU1NTNId30eJVl4aGBuP1ek1hYaF57733zM9+9jPTu3dv88Mf/jCaw7sosajJuXPnzHXXXWdyc3PN3r17zRtvvGEGDhxoSkpKnDZvvfWWkWSqqqrCflbOnz8fs7F+lnXr1pnk5GTzk5/8xBw4cMA8/PDDJiUlxdTW1rbb/p133jE9evQwS5YsMQcPHjTz5883PXv2NPv373faLF682Hg8HrNhwwbz+9//3tx1111m2LBh5i9/+YvT5mJq35XiVZchQ4aYRYsWhf1cnD59Oubj7ahY1OWll14y3/nOd8yLL75oJJm9e/e22U9HjkXxEq+afPGLXzQPP/xw2M9KQ0NDrIYZsWjXpb6+3uTm5pqf//zn5vDhwyYQCJhx48aZ7OzssP1E49hyyYWbgwcPGklm9+7dzrrNmzebhIQE86c//and99TX15uePXua9evXO+sOHTpkJJlAINCm/cKFCy8Ybtr7IYy3eNZl+fLlpn///qaxsdFZN3fuXDN8+PBOjKjzYlWTN954wyQmJppgMOi0WbFihXG73U4NWsPNxx9/HIORRWbcuHGmqKjIeX3+/HmTkZFhSktL221///33m/z8/LB1OTk55pFHHjHGGNPS0mJ8Pp955plnnO319fXG5XKZn/3sZ8aYi6t9V4tHXYz5JNwsXbo0iiOJrmjX5dM+6xga6bGoq8WjJsZ8Em4ee+yxTvU9lmJZl1a7du0ykswf/vAHY0z0ji2X3GmpQCCglJQUjR071lmXm5urxMREVVRUtPueyspKNTc3Kzc311k3YsQIDR48WIFAIOI+3HXXXUpLS9Ott96qX/3qV5EPIgbiWZdAIKDbbrtNycnJzrq8vDxVVVXp448/vojRREesahIIBDRq1KiwB0rm5eUpFArpwIEDYfsbM2aM0tPT9eUvf1nvvPNONIfXIU1NTaqsrAwbT2JionJzcz/z7zgQCIS1lz4ZX2v7o0ePKhgMhrXxeDzKyckJq1Gkte9K8apLq8WLF2vAgAG64YYb9Mwzz4Sd0oynWNSlI6J9jI6meNWk1csvv6yBAwfquuuuU0lJif73f/834n3EQlfVpaGhQQkJCc73RUbr2HLJfSt4MBhUWlpa2LqkpCSlpqZ+5vUMwWBQycnJbb5M0+v1RnQNRL9+/fRv//ZvuuWWW5SYmKhf/vKXuueee7RhwwbdddddEY8lmuJZl2AwqGHDhrXZR+u2/v37d3hf0RSrmgSDwTZPyv70eCUpPT1dK1eu1NixY9XY2Kj/+I//0O23366KigrdeOON0Rheh/z5z3/W+fPn2+3v4cOH233PZ43v0+NvXXehNpHWvivFqy7SJ9ew3XjjjUpNTdWOHTtUUlKiEydO6Pvf/36nx9VZsahLR0TrWBQL8aqJJP3jP/6jhgwZooyMDL377ruaO3euqqqq9Morr0Q2iBjoirqcPXtWc+fO1eTJk50v1YzWsaXLws28efP09NNPX7DNoUOHuqg37Rs4cKCKi4ud1zfddJNqamr0zDPPxCzcXA516WqXQ02GDx+u4cOHO69vvvlmffDBB1q6dKn+8z//M449Q7x9+hgyevRoJScn65FHHlFpaSmP5keY6dOnO38eNWqU0tPTNWHCBH3wwQf63Oc+F8eexV5zc7Puv/9+GWO0YsWKqO+/y8LNE088oW984xsXbHPVVVfJ5/Oprq4ubP25c+d08uRJ+Xy+dt/n8/nU1NSk+vr6sP8zqK2t/cz3dFROTo7Kyso6tY8LuRzq4vP52tzV0Pq6s/VtT7xr4vP52twR0JHxjhs3Tr/97W8v2O9oGzhwoHr06NHu38+FanCh9q3/ra2tVXp6elib1rvpLqb2XSledWlPTk6Ozp07p2PHjoUF4niIRV06IpbH6M6KV03ak5OTI0l6//334x5uYlmX1mDzhz/8Qdu2bXNmbVr3EY1jS5ddczNo0CCNGDHigktycrL8fr/q6+tVWVnpvHfbtm1qaWlx/uL/WnZ2tnr27Kny8nJnXVVVlaqrq+X3+zvV73379oUdyKLtcqiL3+/X22+/rebmZmddWVmZhg8fHpNTUvGuid/v1/79+8P+gZWVlcntdisrK+sz+x3rn5X2JCcnKzs7O2w8LS0tKi8v/8y/Y7/fH9Ze+mR8re2HDRsmn88X1iYUCqmioiKsRpHWvivFqy7t2bdvnxITE9tMtcdDLOrSEbE8RndWvGrSntbbxbv6ONKeWNWlNdgcOXJEW7du1YABA9rsIyrHlg5fetyF7rzzTnPDDTeYiooK89vf/tZcc801YbeB/fGPfzTDhw83FRUVzrpHH33UDB482Gzbts3s2bPH+P1+4/f7w/Z75MgRs3fvXvPII4+Ya6+91uzdu9fs3bvXuQNm9erVZu3atebQoUPm0KFD5l//9V9NYmKi+clPftI1A/8b4lWX+vp64/V6zZQpU8x7771n1q1bZ/r06XPJ3Aoe7Zq03go+ceJEs2/fPrNlyxYzaNCgsFvBly5dajZs2GCOHDli9u/fbx577DGTmJhotm7d2jUD/5R169YZl8tlVq9ebQ4ePGimT59uUlJSnLu9pkyZYubNm+e0f+edd0xSUpJ59tlnzaFDh8zChQvbveU5JSXFvPbaa+bdd981d999d7u3gl+o9vEWj7rs2LHDLF261Ozbt8988MEH5qc//akZNGiQefDBB7t28BcQi7p89NFHZu/evWbTpk1Gklm3bp3Zu3evOXHihNOmI8eieIlHTd5//32zaNEis2fPHnP06FHz2muvmauuusrcdtttXTv4C4h2XZqamsxdd91lrrzySrNv376wW+A/fTduNI4tl2S4+eijj8zkyZNNv379jNvtNg899JA5deqUs7311rq33nrLWfeXv/zF/PM//7Pp37+/6dOnj/n7v//7sH9Yxnxy252kNsvRo0eNMZ+Em5EjR5o+ffoYt9ttxo0bF3brYrzFqy7GGPP73//e3Hrrrcblcpm/+7u/M4sXL471cDskVjU5duyYmTRpkundu7cZOHCgeeKJJ0xzc7Oz/emnnzaf+9znTK9evUxqaqq5/fbbzbZt22I+3s/y/PPPm8GDB5vk5GQzbtw4s3PnTmfbF7/4RTN16tSw9r/4xS/Mtddea5KTk83nP/95s2nTprDtLS0t5sknnzRer9e4XC4zYcIEU1VVFdbmb9X+UtDVdamsrDQ5OTnG4/GYXr16mZEjR5qnnnrKnD17NqbjjFS067Jq1ap2jyELFy502nTk3108dXVNqqurzW233WZSU1ONy+UyV199tZkzZ84l9ZwbY6Jbl9bjcXvLp4/R0Ti2JBhjTMfneQAAAC5tl9xzbgAAADqDcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAq/w/pAxZnU7b1QcAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.02 * (2*4)**-0.5 * 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "OnIIvdoUIjjO",
        "outputId": "d22bef45-2688-4ac2-f231-2d9ad77406e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.021213203435596427"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(model.wpe.weight.flatten()[:100_000].detach().cpu(), bins=50);"
      ],
      "metadata": {
        "id": "l10kLsGcFzAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(model)"
      ],
      "metadata": {
        "id": "ZAbJNo57IyP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(model.decoders[2].mlp.down_proj.weight.flatten().detach().cpu(), bins=50);"
      ],
      "metadata": {
        "id": "DB-vyDHpI28x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŸ¥ GPT model implement with nn.torch transformer"
      ],
      "metadata": {
        "id": "uVkN_q8j7Dpg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8lp68U6i7gkh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}