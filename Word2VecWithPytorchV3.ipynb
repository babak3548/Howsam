{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## pip"
      ],
      "metadata": {
        "id": "BmNi09ugEJGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "e41oSpy2Dw2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q_rusnnEE2v",
        "outputId": "e67e6500-daa3-4e3f-ac33-1d11c9f213a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "iTesZffCEojB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "import string\n",
        "import psutil\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from pprint import pprint\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import mode\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, normalizers, decoders, processors\n",
        "import tiktoken\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, Dataset, IterableDataset, DataLoader"
      ],
      "metadata": {
        "id": "SdiamMUaEQzu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üü• tokenize Tiktoken fast"
      ],
      "metadata": {
        "id": "ocpBR9r9E0Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=load_dataset(\"roneneldan/TinyStories\")"
      ],
      "metadata": {
        "id": "RUTUzg-pGeYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e05c352-abff-4d88-c429-df0c58da7b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvHCVoih5Bap",
        "outputId": "66ba7e09-0fc3-48e3-e12a-6596a9d12f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': (2119719, 1), 'validation': (21990, 1)}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
        "tokenized_train_samples = []\n",
        "for item in tqdm(dataset[\"train\"], desc=\"Tokenizing Train Set\"):\n",
        "    input_ids = tokenizer.encode(item[\"text\"])\n",
        "    tokenized_train_samples.append(np.array(input_ids))"
      ],
      "metadata": {
        "id": "n9l5SC43E5zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_valid_samples = []\n",
        "for item in tqdm(dataset[\"validation\"], desc=\"Tokenizing validation Set\"):\n",
        "    input_ids = tokenizer.encode(item[\"text\"])\n",
        "    tokenized_valid_samples.append(np.array(input_ids))"
      ],
      "metadata": {
        "id": "LrN9LZA03mL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_valid_samples[:1]"
      ],
      "metadata": {
        "id": "cc-VMQ0251vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sumtoks=  sum(len(tok) for tok in tokenized_train_samples)\n",
        "print(sumtoks)"
      ],
      "metadata": {
        "id": "EEIO6-sDIUqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üü• Train Bpe Tokenizer and data loader"
      ],
      "metadata": {
        "id": "FfNEUe3ss4LB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üüß BPE Trainer"
      ],
      "metadata": {
        "id": "CMYf01JHj07X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a BPE tokenizer\n",
        "tokenizer = Tokenizer(models.BPE(unk_token=\"|<unk>|\"))\n",
        "\n",
        "# Use a pre-tokenizer to split text into words\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
        "\n",
        "# Initialize a BPE trainer\n",
        "trainer = trainers.BpeTrainer(\n",
        "    vocab_size=10_000,  # Set the vocabulary size\n",
        "    special_tokens=[\"|<unk>|\", \"<|endoftext|>\"],\n",
        "    min_frequency=2,  # Set the minimum frequency of tokens\n",
        "    )\n",
        "\n",
        "# Train the tokenizer on a custom dataset\n",
        "tokenizer.train_from_iterator(dataset[\"train\"][\"text\"], trainer)\n",
        "\n",
        "# Add special tokens\n",
        "tokenizer.post_processor = processors.TemplateProcessing(\n",
        "    single=\"<|endoftext|> $A\",\n",
        "    special_tokens=[(\"<|endoftext|>\", tokenizer.token_to_id(\"<|endoftext|>\"))],\n",
        ")\n",
        "\n",
        "# Add decoder\n",
        "tokenizer.decoder = decoders.ByteLevel(add_prefix_space=False)\n",
        "\n",
        "# Save the trained tokenizer\n",
        "tokenizer.save(\"bpe-tokenizer_tinystories.json\")\n",
        "\n",
        "#\n",
        "print(f\"üéâ Tokenizer training complete!\")\n",
        "print(f\"üîπ Vocabulary size: {tokenizer.get_vocab_size():,} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0FFXwS3tf9l",
        "outputId": "8d15b6dd-aa76-4fc8-90ad-bb33aa956897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéâ Tokenizer training complete!\n",
            "üîπ Vocabulary size: 10,000 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a BPE tokenizer\n",
        "tokenizer = Tokenizer.from_file(\"bpe-tokenizer_tinystories.json\")\n",
        "print(f\"üéâ Tokenizer training complete!\")\n",
        "print(f\"üîπ Vocabulary size: {tokenizer.get_vocab_size():,} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIB3W1p53lOc",
        "outputId": "2a50cb8d-f64b-4b18-f195-d29d7ba8f630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéâ Tokenizer training complete!\n",
            "üîπ Vocabulary size: 10,000 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = 'They played together all day and became best friends.'\n",
        "tokens = tokenizer.encode(sent)\n",
        "print(tokens.ids)\n",
        "print(tokens.tokens)\n",
        "\n",
        "pprint(tokenizer.decode(tokens.ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "798_gzXZuM5x",
        "outputId": "c61d6ab5-d0fa-466b-be29-1535913ea34d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 546, 667, 462, 378, 252, 161, 1042, 725, 375, 15]\n",
            "['<|endoftext|>', 'They', 'ƒ†played', 'ƒ†together', 'ƒ†all', 'ƒ†day', 'ƒ†and', 'ƒ†became', 'ƒ†best', 'ƒ†friends', '.']\n",
            "'They played together all day and became best friends.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üüß Save and load Tokens with BPE tokenizer"
      ],
      "metadata": {
        "id": "H0gmGOkqIAxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization {train}\n",
        "tokenized_train_samples = []\n",
        "for item in tqdm(dataset[\"train\"], desc=\"Tokenizing Train Set\"):\n",
        "    input_ids = tokenizer.encode(item[\"text\"]).ids\n",
        "    tokenized_train_samples.append(np.array(input_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdaDekSJuq03",
        "outputId": "3262bb29-96e9-4d8c-99e3-5ee1b7183552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokenizing Train Set: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2119719/2119719 [20:22<00:00, 1733.38it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_samples_concat=[]\n",
        "tokenized_train_samples_concat = np.concatenate(tokenized_train_samples)\n",
        "len(tokenized_train_samples_concat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi9uU-62Nq21",
        "outputId": "b0b15efd-297a-45c3-a5f5-e1939dbdef96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "464965814"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tokens as a pytorch file\n",
        "torch.save(torch.tensor(tokenized_train_samples_concat), 'tokenized-train-samples_vocab-10k.pt')"
      ],
      "metadata": {
        "id": "rt_1F7qvQcfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization {validation}\n",
        "tokenized_valid_samples = []\n",
        "for item in tqdm(dataset[\"validation\"], desc=\"Tokenizing Validation Set\"):\n",
        "    input_ids = tokenizer.encode(item[\"text\"]).ids\n",
        "    tokenized_valid_samples.append(np.array(input_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "On0JGjWju6r7",
        "outputId": "fa01a0a9-f830-410c-9aae-cc53ec1d37bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokenizing Validation Set: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21990/21990 [00:12<00:00, 1822.45it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_valid_samples_concat=[]\n",
        "tokenized_valid_samples_concat = np.concatenate(tokenized_valid_samples)\n",
        "len(tokenized_valid_samples_concat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz6unOJpAshB",
        "outputId": "56f2593c-2631-4a24-bfc9-8f4e47d6d001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4673588"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tokens as a pytorch file\n",
        "torch.save(torch.tensor(tokenized_valid_samples_concat), 'tokenized-valid-samples_vocab-10k.pt')"
      ],
      "metadata": {
        "id": "DB6a7nNC8_tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üüß load Data"
      ],
      "metadata": {
        "id": "idrn3C6wkaYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8T883PlZQqrs",
        "outputId": "5b11b881-2160-4746-af1c-cd36fa56c3b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_samples = torch.load('/content/drive/MyDrive/temp/tokenized-train-samples_vocab-10k.pt')"
      ],
      "metadata": {
        "id": "J6_lAe6tFeQJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_train_samples.shape)\n",
        "tokenized_train_samples[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMGmco__VAAa",
        "outputId": "40de50ba-d8ec-42b1-d63c-cc88e7f6f8b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([464965814])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  1, 316, 252,  13, 155])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_valid_samples = torch.load('tokenized-valid-samples_vocab-10k.pt')"
      ],
      "metadata": {
        "id": "fS9EY3Ac90Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_valid_samples_load.shape)\n",
        "print(tokenized_valid_samples_load[:10])\n",
        "tokenized_valid_samples_concat[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7oaiF0NbNLV",
        "outputId": "46baa46d-7a0c-4201-d266-3587f1fd183b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4673588])\n",
            "tensor([   1, 2891,   15, 1014,  309,  159,  866,  460,  161,  223])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1, 2891,   15, 1014,  309,  159,  866,  460,  161,  223])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üüß Custom dataset"
      ],
      "metadata": {
        "id": "6c2dBVc4wf-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TinyStoriesDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, seq_len):\n",
        "        self.seq_len = seq_len\n",
        "        self.data = prepare_data(data, seq_len+1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        return sample[:-1], sample[1:]"
      ],
      "metadata": {
        "id": "1oQvaIZLwkIR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = TinyStoriesDataset(tokenized_train_samples, 128)\n",
        "train_set.data.shape, len(train_set), train_set[0]"
      ],
      "metadata": {
        "id": "ZByVGGuUwenF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit next(iter(train_set))"
      ],
      "metadata": {
        "id": "k47DvjFVxOdw",
        "outputId": "190df032-5420-4d29-fe77-9a7c3e305c46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.5 ¬µs ¬± 104 ns per loop (mean ¬± std. dev. of 7 runs, 100000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üüß DataLoader"
      ],
      "metadata": {
        "id": "x2lJvLkFx-Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenized_train_samples = torch.load('/content/drive/MyDrive/temp/tokenized-train-samples_vocab-10k.pt')\n",
        "tokenized_valid_samples = torch.load('/content/drive/MyDrive/temp/tokenized-valid-samples_vocab-10k.pt')\n",
        "\n",
        "train_set = TinyStoriesDataset(tokenized_train_samples, seq_len=128)\n",
        "valid_set = TinyStoriesDataset(tokenized_valid_samples, seq_len=128)"
      ],
      "metadata": {
        "id": "F5evvjhex63m"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, pin_memory=True), num_workers=4)\n",
        "valid_loader = DataLoader(valid_set, batch_size=32, shuffle=False, pin_memory=True), num_workers=4)"
      ],
      "metadata": {
        "id": "0Acjf4UeyMHz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(iter(train_loader))\n",
        "x_batch.shape, y_batch.shape"
      ],
      "metadata": {
        "id": "qkhNsYnMyUwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader), len(valid_loader)"
      ],
      "metadata": {
        "id": "4Em6sZ_syl2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit next(iter(train_loader))"
      ],
      "metadata": {
        "id": "_RMcGk_qyojK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üüß EDA"
      ],
      "metadata": {
        "id": "wMtdHFsCN2Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_count_stories=[]\n",
        "for tokns in tokenized_train_samples:\n",
        "    token_count_stories.append(len(tokns))"
      ],
      "metadata": {
        "id": "UkQNex4eDn1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_count_stories_np=np.array(token_count_stories)"
      ],
      "metadata": {
        "id": "cxWO9YTOENR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(token_count_stories, bins=50, kde=True)\n",
        "plt.xlabel('Token Count')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Token Counts')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JRcUm7utIHkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sort(token_count_stories_np)[:1000]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LAGEzHvoN-Z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FUbGIq4_OmyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwaY_YcgRayy"
      },
      "source": [
        "# üî¥ **Utils**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(tokens, seq_len):\n",
        "    # Trim tokens so that total length is divisible by seq_len\n",
        "    n_tokens = (tokens.shape[0] // seq_len) * seq_len\n",
        "    tokens = tokens[:n_tokens]\n",
        "\n",
        "    # Reshape to 2D tensor\n",
        "    return tokens.view(-1, seq_len)\n"
      ],
      "metadata": {
        "id": "Vp_t8qCRfNCx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PpKbTUEIRayz"
      },
      "outputs": [],
      "source": [
        "def num_trainable_params(model):\n",
        "  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
        "  return nums"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_time(model, x, num_runs=10):\n",
        "    torch.cuda.synchronize()\n",
        "    start = time.time()\n",
        "    for _ in range(num_runs):\n",
        "        model(*x)\n",
        "    torch.cuda.synchronize()\n",
        "    return (time.time() - start) / num_runs"
      ],
      "metadata": {
        "id": "G6LDfZvmOLcI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üü• Transformer Model from scratch"
      ],
      "metadata": {
        "id": "vOQNBqhXMuYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "TBwuEJI6NNNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAtention(torch.nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        self.qkv_proj = torch.nn.Linear(embed_dim, 3 * embed_dim)\n",
        "        self.out_proj = torch.nn.Linear(embed_dim, embed_dim)\n",
        "    # ÿßÿ≠ÿ™ŸÖÿßŸÑÿß ÿÆÿ∑ÿß ÿßÿ®ÿπÿßÿØ ÿØÿßÿ±ÿØ ÿ≤ŸÖÿßŸÜ ÿ™ÿ±€åŸÜ ŸÖŸÖ⁄©ŸÜ ÿßÿ≥ÿ™ ÿ™ÿ±€åŸÜ ŸÜÿ¥ŸàÿØ\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, embed_dim = x.size()\n",
        "        k,q,v = self.qkv_proj(x).view(batch_size, seq_len, 3, self.num_heads, self.head_dim).transpose(1,2).chunk(3)\n",
        "        # F.scaled_dot_product_attention(q,k,v)\n",
        "        # return self.out_proj(x)\n",
        "        return q"
      ],
      "metadata": {
        "id": "E7h7rW2dDss8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.range(1,24).view(2,3,4)\n",
        "print(x)\n",
        "\n",
        "# /x=x.transpose(1,0)\n",
        "print(x)\n",
        "#"
      ],
      "metadata": {
        "id": "cZ0QUKKhQ8hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45892715-5dc8-4be2-9520-f6b2e4676449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.,  2.,  3.,  4.],\n",
            "         [ 5.,  6.,  7.,  8.],\n",
            "         [ 9., 10., 11., 12.]],\n",
            "\n",
            "        [[13., 14., 15., 16.],\n",
            "         [17., 18., 19., 20.],\n",
            "         [21., 22., 23., 24.]]])\n",
            "tensor([[[ 1.,  2.,  3.,  4.],\n",
            "         [ 5.,  6.,  7.,  8.],\n",
            "         [ 9., 10., 11., 12.]],\n",
            "\n",
            "        [[13., 14., 15., 16.],\n",
            "         [17., 18., 19., 20.],\n",
            "         [21., 22., 23., 24.]]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-bc631cf5fcde>:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  x=torch.range(1,24).view(2,3,4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)\n",
        "y= MultiHeadAtention(4,2)(x)\n",
        "y.shape"
      ],
      "metadata": {
        "id": "a0pQHFFuRGNM",
        "outputId": "1a75d0c3-f2ce-4205-8f96-8c73c8d63bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 4])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 3, got 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-fd711f9de565>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mMultiHeadAtention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-89424fe69ebb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# F.scaled_dot_product_attention(q,k,v)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# return self.out_proj(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n0OCESU31MEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üî¥ **Model from scratch - Howsam**"
      ],
      "metadata": {
        "id": "ZnBQs-C8PNrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üü† Embedding"
      ],
      "metadata": {
        "id": "oP9PxAiBOXG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wte = nn.Embedding(tokenizer.get_vocab_size(), 100)\n",
        "wte(torch.tensor([1, 2, 100])).shape"
      ],
      "metadata": {
        "id": "D3KuSAfszsHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wpe = nn.Embedding(seq_len, 100)\n",
        "wpe(torch.tensor([1, 2, 100])).shape"
      ],
      "metadata": {
        "id": "NN6B1P0tzsBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81fcf250-6857-407e-eebe-519710e29501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = wte(x_batch) + wpe(torch.arange(x_batch.shape[1]))\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMgXEhAwIJxj",
        "outputId": "ba273407-1be3-456a-9991-717990438fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üü† Scaled Dot-Product Attention"
      ],
      "metadata": {
        "id": "CHJ4NWXGR0YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q = k = v = x\n",
        "print(q.shape)\n",
        "\n",
        "mask = torch.tril(torch.ones(seq_len, seq_len))\n",
        "\n",
        "scores = q @ k.transpose(-2, -1) / (k.shape[-1]**0.5)\n",
        "scores.masked_fill_(mask ==0, float(-torch.inf))\n",
        "scores = scores.softmax(dim=-1)\n",
        "print(scores.shape)\n",
        "\n",
        "z = scores @ v\n",
        "z.shape"
      ],
      "metadata": {
        "id": "9j_qy0aIJZXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scores = torch.randn(3, 5, 5)\n",
        "# mask = torch.tril(torch.ones(5, 5))\n",
        "# scores.masked_fill_(mask ==0, float(-torch.inf))\n",
        "# scores = scores.softmax(dim=-1)\n",
        "# scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QptCjesZL96l",
        "outputId": "96a4d348-e97e-4995-f008-3c69df71aee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v):\n",
        "    mask = torch.tril(torch.ones(q.shape[-2], q.shape[-2])).to(device)\n",
        "    scores = q @ k.transpose(-2, -1) / (k.shape[-1]**0.5)\n",
        "    scores.masked_fill_(mask==0, float(-torch.inf))\n",
        "    scores = scores.softmax(dim=-1)\n",
        "    z = scores @ v\n",
        "    return z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mIEMC-FarKJ1",
        "outputId": "646c6067-129c-49a0-90c1-73eb97b75597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_dot_product_attention(x.to(device), x.to(device), x.to(device)).shape"
      ],
      "metadata": {
        "id": "wdt56H82PQqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = torch.randn((128, 1024, 768), device=device)\n",
        "k = torch.randn((128, 1024, 768), device=device)\n",
        "v = torch.randn((128, 1024, 768), device=device)\n",
        "q.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "xK6XgVlePa0n",
        "outputId": "defeb5fa-2049-4ef4-bda6-eb44b5c54951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_dot_product_attention(q, k, v).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "5COTL0OKPxY1",
        "outputId": "196ec6f3-7877-496f-f37c-ffa6ee0af000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_time(scaled_dot_product_attention, (q, k, v), num_runs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsaSSCkaQLtw",
        "outputId": "700691ab-0561-400c-ccc6-3ddd32e4bee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13929617404937744"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.scaled_dot_product_attention(q, k, v, is_causal=True).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmCJ2BV6Unge",
        "outputId": "84a60478-1d6c-4b22-ab8c-9864d1d7f36d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Howsam\\AppData\\Local\\Temp\\ipykernel_2732\\251168821.py:1: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
            "  F.scaled_dot_product_attention(q, k, v, is_causal=True).shape\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.abs(scaled_dot_product_attention(q, k, v) - F.scaled_dot_product_attention(q, k, v, is_causal=True)).max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjrAqzTWU79x",
        "outputId": "b9654265-9aa2-407c-c313-223d6637ffa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.6757e-06, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_time(F.scaled_dot_product_attention, (q, k, v), num_runs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnGXNViJVWzy",
        "outputId": "e3689bc6-8f29-4432-d2c9-ff960e382d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12824971675872804"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üü† Multi Head Attention"
      ],
      "metadata": {
        "id": "rUjFcYeiIE9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class MultiHeadAttention(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.fc1 = nn.Linear(100, 1000)\n",
        "#         self.fc2 = nn.Linear(1000, 100)\n",
        "#         self.fc3 = nn.Linear(1000, 100)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         y = F.relu(self.fc1(x))\n",
        "#         y1 = self.fc2(y)\n",
        "#         y2 = self.fc3(y)\n",
        "#         return F.relu(torch.concat([y1, y2], dim=-1))"
      ],
      "metadata": {
        "id": "gnxYy1oIQcY-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "601d8702-3d97-430e-affc-d934c8994ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mha = MultiHeadAttention()\n",
        "# num_trainable_params(mha)\n",
        "# mha.forward(torch.rand(10, 100)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Et6wVx6f7HmB",
        "outputId": "3271b803-66f5-40db-80b8-de54a91a19df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTConfig:\n",
        "    n_embd: int = 100\n",
        "    n_head: int = 5\n",
        "\n",
        "config = GPTConfig()\n",
        "config.n_embd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        },
        "id": "q10jLOLsuzxi",
        "outputId": "4cd38162-9b16-4ce6-a590-d07bbf66b35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.n_embd = config.n_embd\n",
        "        self.n_head = config.n_head\n",
        "        self.head_size = self.n_embd // self.n_head\n",
        "\n",
        "        self.qkv_proj = nn.Linear(self.n_embd, 3*self.n_embd, bias=False)\n",
        "\n",
        "        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)\n",
        "        self.c_proj.residual = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q, k, v = self.qkv_proj(x).view(B, T, 3*self.n_head, self.head_size).transpose(1, 2).chunk(3, dim=-3)\n",
        "\n",
        "        y = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
        "\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "\n",
        "        y = self.c_proj(y)\n",
        "        return y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2X9b79Iq8l38",
        "outputId": "54a6aa27-6f30-44b6-f23c-c0dba2701bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mha = MultiHeadAttention(config)\n",
        "mha(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "vA3Nw2Riv1Ns",
        "outputId": "d4ecf7e4-5fba-4090-f566-3db7eb340fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d48bc2db6338>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xx = torch.arange(24).view(2, 2, 3, 2)\n",
        "print(xx)\n",
        "xx.reshape(2, 3, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "collapsed": true,
        "id": "Bwed2bE79Yl4",
        "outputId": "4fa4cf5c-b99e-4227-e5e3-5dde19d6e90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0,  1],\n",
            "          [ 2,  3],\n",
            "          [ 4,  5]],\n",
            "\n",
            "         [[ 6,  7],\n",
            "          [ 8,  9],\n",
            "          [10, 11]]],\n",
            "\n",
            "\n",
            "        [[[12, 13],\n",
            "          [14, 15],\n",
            "          [16, 17]],\n",
            "\n",
            "         [[18, 19],\n",
            "          [20, 21],\n",
            "          [22, 23]]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11]],\n",
              "\n",
              "        [[12, 13, 14, 15],\n",
              "         [16, 17, 18, 19],\n",
              "         [20, 21, 22, 23]]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_time(mha.to(device), (x.to(device),), num_runs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "3YRyw8Hu-bXz",
        "outputId": "992034e8-48cc-43b0-8f11-790a415ca2c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0009491205215454102"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üü† Feed Forward (MLP)"
      ],
      "metadata": {
        "id": "WTVewgG-m7nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTConfig:\n",
        "    n_embd: int = 100\n",
        "    n_head: int = 5\n",
        "    f_expnd: float = 4\n",
        "\n",
        "config = GPTConfig()\n",
        "config.n_embd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "R-r7XatDAP4B",
        "outputId": "042eee86-4df9-49a3-bc90-59eed1ca9dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.n_embd = config.n_embd\n",
        "        self.f_expnd = config.f_expnd\n",
        "\n",
        "        self.up_proj = nn.Linear(self.n_embd, int(self.f_expnd*self.n_embd), bias=False)\n",
        "        self.down_proj = nn.Linear(int(self.f_expnd*self.n_embd), self.n_embd, bias=False)\n",
        "        self.down_proj.residual = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.down_proj(F.gelu(self.up_proj(x)))"
      ],
      "metadata": {
        "id": "BTcx4J5Lm66z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "76bb0f38-2c4b-4fcc-8725-1b335715c08b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = FeedForward(config)\n",
        "mlp(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "aDU2oB-PAfXX",
        "outputId": "234e93e4-02e3-4daf-9029-c38812cf6944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trainable_params(mlp)*1000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "JtLY269MBHD3",
        "outputId": "74ff0f0b-018e-4771-8318-f1223abc1f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.0"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_time(mlp, (x, ), num_runs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "FKYxPvrzBQbw",
        "outputId": "07cf6a15-143b-40d6-9411-4853cb3f5233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.013211965560913086"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üü† Decoder Block"
      ],
      "metadata": {
        "id": "ih6sV9ljndzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.n_embd = config.n_embd\n",
        "\n",
        "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
        "        self.mha = MultiHeadAttention(config)\n",
        "\n",
        "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
        "        self.mlp = FeedForward(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.mha(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "Gq1kw31av9DR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0e247701-f3bb-45f4-8334-c46532f55649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = DecoderBlock(config)\n",
        "decoder(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "AweCYj03EtPy",
        "outputId": "dd31b3b5-1b07-4687-e92a-a0687c498ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trainable_params(decoder) * 1e3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "pO5KeXeLFmDk",
        "outputId": "d5c4c562-6800-451e-d742-fd48f050ab03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120.39999999999999"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_time(decoder, (x, ), num_runs=20) * 1e3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "7zAYllgcFsfg",
        "outputId": "ed8b647c-9b42-46c8-fd85-9f8052c98224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52.333009243011475"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üü† GPT"
      ],
      "metadata": {
        "id": "LCzTHf8iitEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTConfig:\n",
        "    vocab_size: int = 10_000\n",
        "    seq_len: int = 128\n",
        "    n_layer: int = 12\n",
        "    n_embd: int = 100\n",
        "    n_head: int = 5\n",
        "    f_expnd: float = 4\n",
        "\n",
        "\n",
        "config = GPTConfig()\n",
        "config.n_embd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "adRz9KC8HbbT",
        "outputId": "9837114c-b354-43d8-f179-c434c39ef4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.wte = nn.Embedding(config.vocab_size, config.n_embd)\n",
        "        self.wpe = nn.Embedding(config.seq_len, config.n_embd)\n",
        "        # self.decoders = nn.Sequential(*[DecoderBlock(config) for _ in range(config.n_layer)])\n",
        "        self.decoders = nn.ModuleList([DecoderBlock(config) for _ in range(config.n_layer)])\n",
        "        self.lnf = nn.LayerNorm(config.n_embd)\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "\n",
        "        self.lm_head.weight = self.wte.weight\n",
        "        # self.lm_head.weight.data.uniform_(-1/self.lm_head.in_features**0.5, 1/self.lm_head.in_features**0.5)\n",
        "        # nn.init.uniform_(self.lm_head.weight, -1/self.lm_head.in_features**0.5, 1/self.lm_head.in_features**0.5)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        std = 0.02\n",
        "        if isinstance(module, nn.Linear):\n",
        "            if hasattr(module, 'residual'):\n",
        "                std *= (2*self.config.n_layer)**-0.5\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=std)\n",
        "            if module.bias is not None:\n",
        "                nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            nn.init.normal_(module.weight, mean=0.0, std=std)\n",
        "\n",
        "    def forward(self, idx):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        x = self.wte(idx) + self.wpe(torch.arange(T, device=device))\n",
        "\n",
        "        # x = self.decoders(x)\n",
        "        for decoder in self.decoders:\n",
        "            x = decoder(x)\n",
        "\n",
        "        x = self.lnf(x)\n",
        "        logits = self.lm_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "Lmrc034JwvSS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "86dd166c-301f-489f-b019-2a3a1f4fe206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT(config).to(device)\n",
        "model(x_batch.to(device)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "FwYwWZ_Z-dV-",
        "outputId": "2fb9fc25-d5d1-400e-8afc-92e800e8889b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 10000])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_trainable_params(model), num_trainable_params(model.decoders), num_trainable_params(model.lm_head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "JdecDmI3-rvN",
        "outputId": "41f80cef-d089-4c6f-8db5-afc4dd51e526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.4578, 1.4448, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_time(model, (x_batch.to(device),), num_runs=100) * 1e3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "gxIo0WS7-z9b",
        "outputId": "e2947ea0-fa16-46d5-af22-cb741f513a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.62372875213623"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üü† Initialization"
      ],
      "metadata": {
        "id": "KEnoziDiCZ84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT(\n",
        "    GPTConfig(\n",
        "        seq_len=256, vocab_size=10_000, n_layer=4, n_embd=256, n_head=4\n",
        "        )).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UVGTRYO9FH3O",
        "outputId": "aa7a81b4-ce82-49cd-ce88-794e321b539c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(model.decoders[0].mha.c_proj.weight.flatten().detach().cpu(), bins=50);"
      ],
      "metadata": {
        "id": "dy1ErMbaCeNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "0.02 * (2*4)**-0.5 * 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "id": "OnIIvdoUIjjO",
        "outputId": "d22bef45-2688-4ac2-f231-2d9ad77406e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    body {\n",
              "      font-size: 24px;\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.021213203435596427"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(model.wpe.weight.flatten()[:100_000].detach().cpu(), bins=50);"
      ],
      "metadata": {
        "id": "l10kLsGcFzAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(model)"
      ],
      "metadata": {
        "id": "ZAbJNo57IyP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(model.decoders[2].mlp.down_proj.weight.flatten().detach().cpu(), bins=50);"
      ],
      "metadata": {
        "id": "DB-vyDHpI28x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üü• GPT model implement with nn.torch transformer"
      ],
      "metadata": {
        "id": "uVkN_q8j7Dpg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8lp68U6i7gkh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}